{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c187034-9615-4829-be18-04ec1045351b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbbaca99-891d-49a4-8647-f9b3767784c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Once upon a time, in a land full of trees, there was a little cherry tree. The cherry tree was very sad because it did not have any friends. All the other trees were big and strong, but the cherry tree was small and weak. The cherry tree was envious of the big trees.\n",
    "\n",
    "One day, the cherry tree felt a tickle in its branches. It was a little spring wind. The wind told the cherry tree not to be sad. The wind said, \"You are special because you have sweet cherries that everyone loves.\" The cherry tree started to feel a little better.\n",
    "\n",
    "As time went on, the cherry tree grew more and more cherries. All the animals in the land came to eat the cherries and play under the cherry tree. The cherry tree was happy because it had many friends now. The cherry tree learned that being different can be a good thing. And they all lived happily ever after.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e77bd29-bd76-4e26-9394-14c09ac155e0",
   "metadata": {},
   "source": [
    "Making Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4614654a-83b4-400f-8a63-aeb4c62d0314",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_dictionary = {}\n",
    "vocab_dictionary.update({\n",
    "  \"<PAD>\": 0,  \n",
    "  \"<UNK>\": 1,\n",
    "  \"<EOS>\": 2\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a8e4259-37f4-419c-b89e-a6bc68e8aa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_num = 3\n",
    "for word in text.split():\n",
    "    if word in vocab_dictionary:\n",
    "        continue\n",
    "\n",
    "    vocab_dictionary.update({word : input_num})\n",
    "    input_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f63675e6-07b3-4fc9-a263-17e42e30c8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<PAD>': 0, '<UNK>': 1, '<EOS>': 2, 'Once': 3, 'upon': 4}\n",
      "{'all': 93, 'lived': 94, 'happily': 95, 'ever': 96, 'after.': 97}\n"
     ]
    }
   ],
   "source": [
    "check_result = dict(list(vocab_dictionary.items())[:5])\n",
    "print(check_result)\n",
    "check_result_rev = dict(list(vocab_dictionary.items())[-5:])\n",
    "print(check_result_rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c16147b0-f629-49e8-9885-6731bb968394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98\n"
     ]
    }
   ],
   "source": [
    "length = len(vocab_dictionary)\n",
    "print(length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749bb970-fdfd-453b-baaa-933eb9348597",
   "metadata": {},
   "source": [
    "Used Tensorflow for learning Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "118c5dfd-ad8d-4229-810b-a11f04f16ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = tf.keras.layers.Embedding(input_dim=length, output_dim=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7f850b88-f0e3-44df-8673-8500485208f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_token(sentence, vocab_dictionary):\n",
    "    tokenized_sentence = []\n",
    "    for word in sentence.split():\n",
    "        tokenized_sentence.append(vocab_dictionary.get(word, vocab_dictionary[\"<UNK>\"]))\n",
    "    tokenized_sentence.append(vocab_dictionary[\"<EOS>\"])\n",
    "    return tokenized_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "33266905-c474-4a92-a858-cc707b7c8660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 13, 1, 15, 18, 2]\n"
     ]
    }
   ],
   "source": [
    "print(return_token(\"there was this cherry tree\", vocab_dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1150ac72-ceef-479c-8d26-eab38eea1af7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_dictionary[\"<UNK>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a6810e77-d3d7-4f85-b650-99b6defced7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 6, 32)\n",
      "tf.Tensor(\n",
      "[[[-0.003157   -0.014812    0.03792368 -0.02091619  0.01136422\n",
      "    0.02568959  0.03052602  0.01494474  0.0370563  -0.04722223\n",
      "   -0.00499951 -0.00804197 -0.02569838  0.00044024 -0.0183773\n",
      "   -0.02174051  0.02419538  0.04637324  0.03925613  0.01871015\n",
      "    0.00112764  0.00648076  0.00476135  0.0254074  -0.00088173\n",
      "   -0.00544335 -0.0077469  -0.00935403 -0.04301229  0.00157953\n",
      "   -0.00064641  0.04805514]\n",
      "  [-0.00232135  0.01690663  0.04038136  0.04205063 -0.04429014\n",
      "    0.03793261 -0.01431119  0.04121277  0.0496351  -0.03905869\n",
      "   -0.03948243  0.04994576  0.0128164   0.02393854 -0.02144944\n",
      "   -0.03742179  0.0485835  -0.02214026  0.0043214  -0.04176843\n",
      "   -0.03972516  0.0436716  -0.04260694  0.0006148  -0.04369352\n",
      "    0.00517162 -0.00374572 -0.0370044  -0.04598261  0.00472756\n",
      "   -0.04499986 -0.01892742]\n",
      "  [ 0.00095876  0.01741079 -0.04889452 -0.0134821   0.00528406\n",
      "   -0.04564824  0.03083933  0.04167619  0.03084892 -0.01127889\n",
      "   -0.00551737  0.03605169  0.03388561  0.04080415 -0.02056587\n",
      "    0.02285551  0.03390694  0.01072525 -0.00160851  0.0020294\n",
      "    0.00535534 -0.04832809 -0.03862326 -0.01167281  0.04454224\n",
      "    0.02721251 -0.03854864 -0.03440021  0.01835303  0.01112808\n",
      "    0.03342632  0.00297655]\n",
      "  [-0.02862673  0.01109394  0.00138904  0.03014538 -0.0467032\n",
      "    0.03647986  0.01367576 -0.02300584 -0.00071529  0.03029522\n",
      "    0.04751122  0.00171028 -0.00892951 -0.008097   -0.04738754\n",
      "    0.00832137  0.0074337  -0.04807258 -0.01058291 -0.04377632\n",
      "   -0.03347781 -0.03695829  0.04260633 -0.01176168  0.03736534\n",
      "   -0.0367709  -0.00488576 -0.02321224  0.03424731  0.04879175\n",
      "    0.01378569 -0.03761582]\n",
      "  [-0.04898982 -0.0130838   0.04603634 -0.01424043  0.04838483\n",
      "    0.04448601  0.03486821 -0.01981403  0.00610248  0.01837906\n",
      "    0.03617251 -0.03430783 -0.04241453  0.00118815  0.00403019\n",
      "    0.02945992  0.03135255  0.02461859 -0.03646784 -0.01414074\n",
      "    0.04325116  0.03363308  0.0283046  -0.0172657  -0.01717888\n",
      "    0.00632589  0.00576495  0.03838317  0.00211791  0.00235357\n",
      "   -0.01108842 -0.00738315]\n",
      "  [ 0.04760684  0.02361084 -0.00614504  0.04662274  0.03750262\n",
      "   -0.02538912 -0.03423987  0.03298891  0.04277388  0.04324367\n",
      "   -0.03675609 -0.02927201  0.0350554  -0.01313104 -0.00305966\n",
      "    0.01828342  0.03679948 -0.02977103  0.03715935  0.03532071\n",
      "   -0.03825928 -0.04290129  0.0242978   0.02124064 -0.00866608\n",
      "   -0.0276191  -0.04335938 -0.00247493  0.00536799  0.03145111\n",
      "    0.00785991  0.02729266]]], shape=(1, 6, 32), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "word = \"cherry\"\n",
    "token = return_token(word, vocab_dictionary)\n",
    "token_in_tensor = tf.constant([tokens])\n",
    "\n",
    "embedding_vectors = embedding_layer(token_in_tensor)\n",
    "print(embedding_vectors.shape)\n",
    "print(embedding_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537b498a-ea20-4814-8077-c546c4ce90b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480c3141-06a2-472e-a0db-adc65138741f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f70bea-7e8b-47df-9195-b5398be37573",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
